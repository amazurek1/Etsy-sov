{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/skimage/io/_io.py:49: UserWarning: `as_grey` has been deprecated in favor of `as_gray`\n",
      "  warn('`as_grey` has been deprecated in favor of `as_gray`')\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python2\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Sep 11 22:52:51 2017\n",
    "\n",
    "@author: Tu Bui tb00083@surrey.ac.uk\n",
    "\"\"\"\n",
    "\n",
    "import sys,os\n",
    "from PIL import Image\n",
    "import StringIO\n",
    "import math\n",
    "import subprocess\n",
    "import caffe\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.io import savemat\n",
    "import time\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "\n",
    "MODEL_WEIGHTS_PATH = 'model/triplet1_InceptionV1_InceptionV1_halfshare_inception4e_ld256_triplet_sketchy_iter_31200.caffemodel'\n",
    "MODEL_SPEC_PATH = 'model/deploy_images_net1_InceptionV1_InceptionV1_halfshare_inception4e_ld256_triplet_sketchy.prototxt'\n",
    "\n",
    "\n",
    "\n",
    "GPU_DEV = 0\n",
    "LAYER_DIMS=256\n",
    "mean_pixel = np.array([104, 117, 123],dtype=np.float32)[:,None,None]\n",
    "\n",
    "def get_net(caffemodel, deploy_file, use_gpu=True):\n",
    "    \"\"\"\n",
    "    Returns an instance of caffe.Net\n",
    "\n",
    "    Arguments:\n",
    "    caffemodel -- path to a .caffemodel file\n",
    "    deploy_file -- path to a .prototxt file\n",
    "\n",
    "    Keyword arguments:\n",
    "    use_gpu -- if True, use the GPU for inference\n",
    "    \"\"\"\n",
    "    if use_gpu:\n",
    "        caffe.set_mode_gpu()\n",
    "        caffe.set_device(GPU_DEV)\n",
    "\n",
    "    # load a new model\n",
    "    return caffe.Net(deploy_file, caffe.TEST, weights = caffemodel)\n",
    "\n",
    "\n",
    "def extractitem(net, mean_pixel, fname):\n",
    "  \n",
    "    DATA_LAYER = net.inputs[0]\n",
    "    net.blobs[DATA_LAYER].reshape(1,3,224,224) \n",
    "    try:\n",
    "       input_image = Image.fromarray(np.uint8(caffe.io.load_image(fname)*255))#.resize((256,256),Image.BILINEAR).crop((16,16,240,240))\n",
    "       #resize\n",
    "       sf = 256.0/max(input_image.size)\n",
    "       input_image = input_image.resize((int(input_image.width*sf),int(input_image.height*sf)),Image.BILINEAR)\n",
    "       pw = (256 - input_image.width)/2\n",
    "       ph = (256 - input_image.height)/2\n",
    "       input_image = np.array(input_image)\n",
    "         \n",
    "       #make sure image is RGB format\n",
    "       if input_image.ndim == 2:\n",
    "         input_image = input_image[...,None]\n",
    "         input_image = np.repeat(input_image,3, axis=2)\n",
    "          \n",
    "       #pad to make 256x256\n",
    "       input_image = np.pad(input_image,((ph,ph),(pw,pw),(0,0)), mode='edge')\n",
    "         \n",
    "       #crop\n",
    "       input_image = input_image[16:240,16:240]\n",
    "       \n",
    "       sys.stdout.flush()\n",
    "       transformed_image = np.array(input_image,dtype=np.float32)[:,:,::-1].transpose(2,0,1) - mean_pixel\n",
    "       sys.stdout.flush()\n",
    "       net.blobs[DATA_LAYER].data[...] = transformed_image\n",
    "       sys.stdout.flush()\n",
    "       _ = net.forward()\n",
    "       sys.stdout.flush()\n",
    "       blobname=net.blobs.keys()[-1] #should be feat_p for image and feat_a for sketch\n",
    "       prediction = net.blobs[blobname].data.squeeze()\n",
    "    \n",
    "    \n",
    "    except Exception as e:\n",
    "       s=str(e)\n",
    "       print('WARNING: Image was unusable %s' % fname)\n",
    "       print(s)\n",
    "       prediction = np.zeros(LAYER_DIMS).astype(np.float32)\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "#filepaths is a list of the filepaths for each image file\n",
    "filepaths = []\n",
    "for subdir, dirs, files in os.walk(u'/root/Etsy-sov/SBIR_regression/lampshades_images/il'):\n",
    "    for filename in files:\n",
    "        filepath = subdir + os.sep + filename\n",
    "\n",
    "        if filepath.endswith(\".jpg\") or filepath.endswith(\".png\"):\n",
    "            #print (filepath)\n",
    "            filepaths.append(filepath)\n",
    "            \n",
    "#uses the full filepath for each image to create the numpy array\n",
    "for file in filepaths:\n",
    "    if __name__ == \"__main__\":\n",
    "        net = get_net(MODEL_WEIGHTS_PATH, MODEL_SPEC_PATH)\n",
    "        sample_img = '{}'.format(file)\n",
    "        feat = extractitem(net, mean_pixel, sample_img)\n",
    "        np.save(os.path.join('lampshades_images','{}_np'.format(file)), feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prints out all the filepaths for the images\n",
    "filepaths = []\n",
    "for subdir, dirs, files in os.walk(u'/root/SBIR_regression/lampshades_images/lampshades/il'):\n",
    "    for filename in files:\n",
    "        filepath = subdir + os.sep + filename\n",
    "\n",
    "        if filepath.endswith(\".jpg\") or filepath.endswith(\".png\"):\n",
    "            #print (filepath)\n",
    "            filepaths.append(filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
